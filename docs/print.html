<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>AirlandKK&#x27;学习笔记</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="algorithm/about.html"><strong aria-hidden="true">1.</strong> 数据结构与算法</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="algorithm/inear_structure/algorithmAbout.html"><strong aria-hidden="true">1.1.</strong> 线性结构</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="algorithm/inear_structure/list.html"><strong aria-hidden="true">1.1.1.</strong> 线性结构</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="bigData/about.html"><strong aria-hidden="true">2.</strong> 大数据</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="bigData/linux/aboutlinux.html"><strong aria-hidden="true">2.1.</strong> Linux</a></li><li class="chapter-item expanded "><a href="bigData/Hadoop/hadoopabout.html"><strong aria-hidden="true">2.2.</strong> Hadoop</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="bigData/Hadoop/typeandbuild.html"><strong aria-hidden="true">2.2.1.</strong> 三种模式及搭建环境</a></li><li class="chapter-item expanded "><a href="bigData/Hadoop/HDFS.html"><strong aria-hidden="true">2.2.2.</strong> HDFS</a></li><li class="chapter-item expanded "><a href="bigData/Hadoop/question.html"><strong aria-hidden="true">2.2.3.</strong> 问题</a></li><li class="chapter-item expanded "><a href="bigData/Hadoop/facetest.html"><strong aria-hidden="true">2.2.4.</strong> 面试</a></li></ol></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">AirlandKK&#x27;学习笔记</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="算法"><a class="header" href="#算法">算法</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="线性结构"><a class="header" href="#线性结构">线性结构</a></h1>
<p>线性结构是一个有序数据元素的集合。 常用的线性结构有：线性表，栈，队列，双队列，串(一维数组)。
关于广义表、数组(高维)，是一种非线性的数据结构。 常见的非线性结构有：二维数组，多维数组，广义表，树(二叉树等)，图</p>
<h2 id="特征"><a class="header" href="#特征">特征</a></h2>
<ol>
<li>集合中必存在唯一的一个&quot;第一个元素&quot;；</li>
<li>集合中必存在唯一的一个&quot;最后的元素&quot;；</li>
<li>除最后元素之外，其它数据元素均有唯一的&quot;后继&quot;；</li>
<li>除第一元素之外，其它数据元素均有唯一的&quot;前驱&quot;。
数据结构中线性结构指的是数据元素之间存在着“一对一”的线性关系的数据结构。<br />
如（a0,a1,a2,.....,an）,a0为第一个元素，an为最后一个元素，此集合即为一个线性结构的集合。
相对应于线性结构，非线性结构的逻辑特征是一个结点元素可能对应多个直接前驱和多个后继。</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="线性结构-1"><a class="header" href="#线性结构-1">线性结构</a></h1>
<h2 id="什么是线性表"><a class="header" href="#什么是线性表">什么是线性表？</a></h2>
<p>多项式表示问题的启示：</p>
<ol>
<li>同一个问题可以有不同的表示（存储）方式</li>
<li>有一类共性问题：有序线性序列的组织和管理</li>
</ol>
<p>“线性表”：由同类型数据元素构成有序序列的线性结构</p>
<ul>
<li>表中元素个数称为线性表的<strong>长度</strong></li>
<li>线性表没有元素时，称为<strong>空表</strong></li>
<li>表起始位置称为<strong>表头</strong>，表结束位置称<strong>表尾</strong></li>
</ul>
<p><img src="algorithm/inear_structure/img/list1.png" alt="线性表的增删改查" /></p>
<h3 id="线性表的链式存储实现"><a class="header" href="#线性表的链式存储实现">线性表的链式存储实现</a></h3>
<ul>
<li>不要求逻辑上相邻的两个元素物理上也相邻；通过“链”建立起数据元素之间的逻辑关系。</li>
<li>插入、删除不需要移动数据元素，只需要修改“链”。</li>
</ul>
<h4 id="广义表"><a class="header" href="#广义表">广义表</a></h4>
<p>我们知道了一元多项式的表示，那么二元多项式又该如何表示？<br />
<img src="algorithm/inear_structure/img/list1.png" alt="" /></p>
<ul>
<li>广义表是线性表的推广</li>
<li>对于线性表而言，n个元素都是基本的单元素；</li>
<li>广义表中，这些元素不仅可以是单元素也可以是另一个广义表。</li>
</ul>
<h4 id="多重链表"><a class="header" href="#多重链表">多重链表</a></h4>
<p>链表中的节点可能同时隶属于多个链</p>
<ul>
<li>多重链表中结点的<strong>指针域会有多个</strong>，如前面例子包含了Next和SubList两个指针域；</li>
<li>但包含两个指针域的链表并不一定是多重链表，比如在<strong>双向链表不是多重链表。</strong></li>
<li>多重链表有广泛的用途：基本上如树、图这样相对复杂的数据结构都可以采用多重链表方式实现存储。<br />
<img src="algorithm/inear_structure/img/list3.png" alt="" /><br />
<img src="algorithm/inear_structure/img/list4.png" alt="" /> 这就是稀疏矩阵用十字链表解决的思路<br />
<img src="algorithm/inear_structure/img/list5.png" alt="" /></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="大数据"><a class="header" href="#大数据">大数据</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linux"><a class="header" href="#linux">linux</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hadoop1x和hadoop2x区别"><a class="header" href="#hadoop1x和hadoop2x区别">Hadoop1.x和Hadoop2.x区别</a></h1>
<ul>
<li>Hadoop1.x组成
<ul>
<li>MapReduce（计算+资源调度）</li>
<li>HDFS（数据存储）</li>
<li>Common（辅助工具）</li>
</ul>
</li>
<li>Hdoop2.x组成
<ul>
<li>MapReduce（计算）</li>
<li><strong>Yarn（资源调度）</strong></li>
<li>HDFS（数据存储）</li>
<li>Common（辅助工具）</li>
</ul>
</li>
</ul>
<p>在Hadoop1.X时代，Hadoop中的MapRudece同时处理业务逻辑运算和资源的调度，耦合性较大，在Hadoop2.X时代，增加了Yarn。Yarn只负责资源的调度，MapReduce只负责运算。</p>
<h1 id="hdfs架构概述"><a class="header" href="#hdfs架构概述">HDFS架构概述</a></h1>
<ul>
<li><strong>NameNode（nn）</strong>-类似目录：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。</li>
<li><strong>DataNode（dn）</strong>-类似真正存储的数据：在本地文件系统存储文件块数据，以及块数据的校验和。</li>
<li>Secondary NameNode（2nn）：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</li>
</ul>
<h1 id="yarn架构概述"><a class="header" href="#yarn架构概述">YARN架构概述</a></h1>
<ol>
<li><strong>ResourceManager（RM）主要作用如下</strong>
<ol>
<li>处理客户端请求</li>
<li>监控NodeManager</li>
<li>启动或监控ApplicationMaster</li>
<li>资源的分配与调度</li>
</ol>
</li>
<li><strong>NodeManager（NM）主要作用如下</strong>
<ol>
<li>管理单个节点上的资源</li>
<li>处理来自ResourceManager的命令</li>
<li>处理来自ApplicationMaster的命令</li>
</ol>
</li>
<li>ApplicationMaster（AM）作用如下
<ol>
<li>负责数据的切分</li>
<li>为应用程序申请资源并分配给内部的任务</li>
<li>任务的监控与容错</li>
</ol>
</li>
<li>Container
<ol>
<li>Container是YARN中资源抽象，它封住了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。</li>
</ol>
</li>
</ol>
<h1 id="maprudece架构概述"><a class="header" href="#maprudece架构概述">MapRudece架构概述</a></h1>
<p>MapReduce将计算过程分为两个阶段：Map和Reduce</p>
<ol>
<li>Map阶段并行处理输入数据</li>
<li>Reduce阶段对Map结果进行汇总</li>
</ol>
<h1 id="大数据技术生态系统"><a class="header" href="#大数据技术生态系统">大数据技术生态系统</a></h1>
<table><thead><tr><th>数据来源层</th><th>数据传输层</th><th>数据存储层</th><th>资源管理层</th><th>数据计算层</th><th>任务调度层</th><th>配置和调度</th><th>业务模型层</th></tr></thead><tbody>
<tr><td>数据库（结构化数据）</td><td>Sqoop数据传递</td><td><strong>HDFS文件存储</strong></td><td>YARN资源管理</td><td>MapReduce<u>离线</u>计算（1. <strong>Hive数据查询</strong>（javaEE）、2. Mahout数据挖掘（算法））</td><td>Oozie任务调度、Azkaban任务调度</td><td>Zookeeper（容易改变的配置信息）</td><td>业务模型、数据库可视化、业务应用</td></tr>
<tr><td>文件日志（半结构化数据）</td><td>Flume日志收集</td><td><strong>HDFS文件存储</strong>/HBase非关系型数据库</td><td>YARN资源管理</td><td>Spark Core内存计算 （<u>离线</u>1. Spark Mlib数据挖掘、2.Spark R数据分析、3.Spark Sql数据查询；<u>准实时批处理</u>Spark Streaming实时计算）/Flink 流处理</td><td>Oozie任务调度、Azkaban任务调度</td><td>Zookeeper（容易改变的配置信息）</td><td>业务模型、数据库可视化、业务应用</td></tr>
<tr><td>视频、ppt等（非结构化数据）</td><td>Kafka消息队列</td><td>Kafka缓存一些数据</td><td></td><td></td><td></td><td>Zookeeper（容易改变的配置信息）</td><td>业务模型、数据库可视化、业务应用</td></tr>
</tbody></table>
<p><img src="bigData/Hadoop/img/image-20211226125619030.png" alt="image-大数据技术生态系统" /></p>
<h1 id="推荐系统项目框架"><a class="header" href="#推荐系统项目框架">推荐系统项目框架</a></h1>
<p><img src="bigData/Hadoop/img/image-20211226132415451.png" alt="image-推荐系统" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="单机模式-stonealone"><a class="header" href="#单机模式-stonealone">单机模式 stonealone</a></h1>
<ul>
<li>grep案例</li>
<li>WordCount案例</li>
</ul>
<h1 id="伪分布式模式"><a class="header" href="#伪分布式模式">伪分布式模式</a></h1>
<ul>
<li>所有配置都是按照分布式来的</li>
<li>但是只有一台服务器</li>
</ul>
<h1 id="虚拟机环境准备"><a class="header" href="#虚拟机环境准备">虚拟机环境准备</a></h1>
<pre><code class="language-shell">vim /etc/udev/rules.d/70-persistent-net.rules //修改最后为eth0
vim /etc/sysconfig/network-scripts/ifcfg-eth0 

</code></pre>
<p>https://juejin.cn/post/6991352348471722014#heading-18</p>
<p>https://juejin.cn/post/6844904114980126734#heading-1</p>
<pre><code class="language-shell"># 设置环境变量
$ vim /etc/profile
# 进入之后在文件末尾追加如下内容：
#java
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
export JRE_HOME=${JAVA_HOME}/jre    
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib    
export PATH=${JAVA_HOME}/bin:$PATH
#hadoop
export HADOOP_HOME=/opt/software/hadoop-3.3.1
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib&quot;
export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native:$JAVA_LIBRARY_PATH
# 使环境变量生效
$ source /etc/profile

	&lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/opt/software/hadoop-3.3.1/data/tmp&lt;/value&gt;
    &lt;/property&gt;
</code></pre>
<h1 id="配置免密登录"><a class="header" href="#配置免密登录">配置免密登录</a></h1>
<h4 id="1编辑etchosts"><a class="header" href="#1编辑etchosts">1.编辑/etc/hosts</a></h4>
<p>(下面的 IPn 表示如 192.168.1.1 格式的云服务器外网 IP 地址。注意，如果是指向本机的 IP，请用内网 IP 地址代替)</p>
<pre><code class="language-XML">IP1 ZKK01
IP2 slave1
IP3 slave2
</code></pre>
<h4 id="2切换到hadoop用户生成id_rsapub我是root用户所以不用切换和赋权"><a class="header" href="#2切换到hadoop用户生成id_rsapub我是root用户所以不用切换和赋权">2.切换到hadoop用户生成id_rsa.pub(我是root用户所以不用切换和赋权)</a></h4>
<pre><code class="language-shell">su hadoop
cd ~
ssh-keygen -t rsa
cd ~/.ssh/
cat id_rsa.pub &gt;&gt; authorized_keys
#chmod 700 /home/hadoop/.ssh
#chmod 644 /home/hadoop/.ssh/authorized_keys
</code></pre>
<p>---<strong>以上命令所有云服务器都要运行</strong>---</p>
<h4 id="3交换共享-id_rsapub-的内容"><a class="header" href="#3交换共享-id_rsapub-的内容">3.交换共享 id_rsa.pub 的内容</a></h4>
<p>（如果搭建伪分布模式，则可以略过交换共享这一步，直接进行 ssh 的测试）--我就是伪分布式</p>
<h5 id="1-master-云服务器操作"><a class="header" href="#1-master-云服务器操作">1) master 云服务器操作</a></h5>
<pre><code>scp /home/hadoop/.ssh/authorized_keys slave2:/home/hadoop/.ssh/
</code></pre>
<h5 id="2-slave1-云服务器操作"><a class="header" href="#2-slave1-云服务器操作">(2) slave1 云服务器操作</a></h5>
<pre><code>scp /home/hadoop/.ssh/authorized_keys slave3:/home/hadoop/.ssh/
</code></pre>
<h5 id="3-slave2-云服务器操作"><a class="header" href="#3-slave2-云服务器操作">(3) slave2 云服务器操作</a></h5>
<pre><code>scp /home/hadoop/.ssh/authorized_keys master:/home/hadoop/.ssh/
</code></pre>
<ul>
<li>这一步的最终目的是让所有云服务器的 <strong>authorized_keys</strong> 内容都包含各自的 <strong>id_rsa.pub</strong> 信息，且内容相同。</li>
</ul>
<h5 id="4-测试配置是否成功"><a class="header" href="#4-测试配置是否成功">(4) 测试配置是否成功</a></h5>
<h6 id="master-上执行命令"><a class="header" href="#master-上执行命令">master 上执行命令：</a></h6>
<pre><code>ssh slave1
quit
ssh slave2
quit
</code></pre>
<h6 id="slave1-上执行命令"><a class="header" href="#slave1-上执行命令">slave1 上执行命令：</a></h6>
<pre><code>ssh master
quit
ssh slave2
quit
</code></pre>
<h6 id="slave2-上执行命令"><a class="header" href="#slave2-上执行命令">slave2 上执行命令：</a></h6>
<pre><code>ssh master
quit
ssh slave1
quit
</code></pre>
<ul>
<li>需要确保所有云服务器能够相互 <code>ssh</code> 通过。</li>
<li>第一次进行 <code>ssh</code> 需要密码登录。输完密码之后，选择 <code>yes</code> 保存记录。之后就不再需要输入密码登录了。</li>
<li>如果出现异常情况，可重启服务再尝试：<code>sudo service sshd service</code>。</li>
</ul>
<h1 id="修改配置文件"><a class="header" href="#修改配置文件">修改配置文件</a></h1>
<h4 id="1-etcprofile-配置环境变量"><a class="header" href="#1-etcprofile-配置环境变量">1. /etc/profile 配置环境变量</a></h4>
<pre><code class="language-shell">vim /opt/software/hadoop-3.3.1/etc/profile
</code></pre>
<p><img src="bigData/Hadoop/img/image-20211228212644519.png" alt="环境变量" /></p>
<pre><code class="language-XML">#java
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
#hadoop
export HADOOP_HOME=/opt/software/hadoop-3.3.1
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib&quot;
export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native:$JAVA_LIBRARY_PATH
</code></pre>
<h4 id="2-使环境变量生效"><a class="header" href="#2-使环境变量生效">2. 使环境变量生效</a></h4>
<pre><code class="language-she'l">source /etc/profile
</code></pre>
<h1 id="集群配置"><a class="header" href="#集群配置">集群配置</a></h1>
<p><img src="bigData/Hadoop/img/image-20211228203703927.png" alt="image-20211228203703927" /></p>
<p>也可以都配置在同一台机子上如果内存够的话..</p>
<p>四个默认核心文件</p>
<p>四个自定义文件：</p>
<pre><code class="language-shell">#配置路径
/opt/software/hadoop-3.3.1/etc/hadoop
</code></pre>
<ul>
<li>配置core-site.xml</li>
</ul>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;!--指定HDFS中NameNode的地址--&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://ZKK01:8020&lt;/value&gt;
		&lt;!-- 除了8020 还有9000等 --&gt;
    &lt;/property&gt;
    &lt;!--指定Hadoop运行时产生文件的存储目录--&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/opt/software/hadoop-3.3.1/data/tmp&lt;/value&gt;
    &lt;/property&gt;
    &lt;!--配置HDFS网页登录使用的静态用户为zkk，可以不配置--&gt;
     &lt;property&gt;
        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
        &lt;value&gt;zkk&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;

</code></pre>
<ul>
<li>配置hdfs-site.xml</li>
</ul>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;configuration&gt;
    &lt;!-- nn web端访问地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;
        &lt;value&gt;ZKK01:9870&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定HDFS副本的数量 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 2nn web端访问地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;ZKK01:9870&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<ul>
<li>配置yarn-site.xml</li>
</ul>
<pre><code class="language-xml">&lt;configuration&gt;
    &lt;!-- 指定MR走shuffle--&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
	&lt;/property&gt;
    
    &lt;!--指定ResourceManager地址--&gt;
    &lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
		&lt;value&gt;ZKK01&lt;/value&gt;
	&lt;/property&gt;

    &lt;!--环境变量的继承--&gt;
    &lt;!--3.1.3以上的版本解决了这个bug可以不配置--&gt;
&lt;/configuration&gt;
</code></pre>
<ul>
<li>配置mapred-site.xml</li>
</ul>
<pre><code class="language-xml">&lt;configuration&gt;
    &lt;!--指定MapReduce程序运行在Yarn上--&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
		&lt;value&gt;yarn&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<h1 id="群起集群"><a class="header" href="#群起集群">群起集群</a></h1>
<h2 id="1-配置works"><a class="header" href="#1-配置works">1. 配置Works</a></h2>
<pre><code class="language-shell">vim /opt/software/hadoop-3.3.1/etc/hadoop/workers
</code></pre>
<pre><code class="language-xml">#默认为local 把local注释掉
ZKK01
</code></pre>
<h2 id="2-启动集群"><a class="header" href="#2-启动集群">2. 启动集群</a></h2>
<ol>
<li><strong>如果集群是第一次启动</strong>，需要在ZKK01节点格式化NameNode（注意：格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到以往数据。如果集群在运行中报错，需要重新格式化NameNode的话，一定要先停止namenode和datanode进程，并且要删除所有机器的data和logs目录，然后再进行格式化）</li>
</ol>
<pre><code class="language-shell">[root@ZKK01 hadoop-3.3.1]# hdfs namenode -format
</code></pre>
<ol start="2">
<li>启动HDFS</li>
</ol>
<pre><code class="language-shell">[root@ZKK01 hadoop-3.3.1]# sbin/start-dfs.sh
</code></pre>
<p>/opt/software/hadoop-3.3.1/data/tmp/dfs/name/current</p>
<p><img src="bigData/Hadoop/img/image-20211228210452263.png" alt="image-20211228210452263" /></p>
<ul>
<li>启动过程中遇到报错（<strong>root权限问题?</strong>）</li>
</ul>
<p><img src="bigData/Hadoop/img/image-20211228210901959.png" alt="image-20211228210901959" /></p>
<p>解决办法：</p>
<ul>
<li>
<p>方法一：</p>
<p>在Hadoop安装目录下找到sbin文件夹</p>
<p>在里面修改四个文件</p>
<p>1、对于start-dfs.sh和stop-dfs.sh文件，添加下列参数：</p>
<pre><code class="language-xml">#!/usr/bin/env bash
HDFS_DATANODE_USER=root
HADOOP_SECURE_DN_USER=hdfs
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root
</code></pre>
<p>2、对于start-yarn.sh和stop-yarn.sh文件，添加下列参数：</p>
<pre><code class="language-shell">#!/usr/bin/env bash
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root

</code></pre>
<p>重新开始start…就可以。</p>
</li>
<li>
<p>方法二（推荐采用）</p>
<p><img src="bigData/Hadoop/img/image-20211228211221848.png" alt="错误解决" /></p>
<ul>
<li>
<pre><code class="language-shell">cd /etc/hadoop/
vim hadoop-env.sh
</code></pre>
</li>
<li>
<pre><code class="language-xml">export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root

</code></pre>
</li>
<li>
<p>Now save and start yarn, hdfs service and check that it works.</p>
<p>我们在hadoop-env.sh文件中也可以找到如下的描述</p>
<p>To prevent accidents, shell commands be (superficially) locked to only allow certain users to execute certain subcommands.</p>
<p>为了防止发生意外，仅（部分）锁定shell命令以仅允许某些用户执行某些子命令。</p>
<p>It uses the format of (command)_(subcommand)_USER.For example, to limit who can execute the namenode command,export HDFS_NAMENODE_USER=hdfs</p>
<p>使用“命令_子命令_用户”，例如，通过使用export HDFS_NAMENODE_USER=hdfs来限制哪个用户可以执行namenode命令。参考stackoverflow上的相关讨论</p>
</li>
</ul>
</li>
</ul>
<ol start="3">
<li>
<p>Web访问NameNode Web地址</p>
<ul>
<li>
<p>IP：9870（配置hdfs-site.xml时候设置的）</p>
</li>
<li>
<p>查看HDFS上存储的数据信息</p>
</li>
<li>
<p>我是用云服务器的 所以记得在云服务器防火墙管理中添加可访问端口（其他端口同理）<img src="bigData/Hadoop/img/image-20211228213933435.png" alt="防火墙" /></p>
</li>
</ul>
</li>
<li>
<p>在配置了<strong>ResourceManager</strong>的节点（ZKK01）启动YARN</p>
</li>
</ol>
<ul>
<li>
<pre><code class="language-shell">[root@ZKK01 hadoop-3.3.1]# sbin/start-yarn.sh 
</code></pre>
</li>
<li>
<p><img src="bigData/Hadoop/img/image-20211228214842406.png" alt="image-20211228214842406" /></p>
</li>
</ul>
<ol start="5">
<li>Web端查看YARN的ResourceManager
<ul>
<li>IP：8088</li>
<li>查看YARN上运行的Job信息</li>
</ul>
</li>
</ol>
<h1 id="集群基本测试"><a class="header" href="#集群基本测试">集群基本测试</a></h1>
<h4 id="1上传文件到集群"><a class="header" href="#1上传文件到集群">1.上传文件到集群</a></h4>
<p>上传小文件</p>
<pre><code class="language-shell">hadoop fs -mkdir /wcinput
hadoop fs -put wcinput/wc.input /wcinput
</code></pre>
<p><img src="bigData/Hadoop/img/image-20220103153532117.png" alt="image-20220103153532117" /></p>
<p>网页中操作，要在本地机配置hosts文件</p>
<h4 id="2查看hdfs在磁盘存储文件内容"><a class="header" href="#2查看hdfs在磁盘存储文件内容">2.查看HDFS在磁盘存储文件内容</a></h4>
<ol>
<li>查看：页面只是一个链接，真实的东西都存在data节点上。</li>
</ol>
<pre><code class="language-shell">cd data/tmp/dfs/data/current/BP-912934988-110.42.160.28-1641041699096/current/finalized/subdir0/subdir0/

cat blk_1073741825
zhangkeke hadoop zhangsan lisi wangwu 
liuliu wangmengting xingguo 
zhangkeke 
keke keke keke keke keke hadoop
hive hivehive

</code></pre>
<ol start="2">
<li>
<p>拼接：默认块大小128MB如上传一个jdk tar包，其实也是放在节点上 可通过拼接命令查看</p>
<p><img src="bigData/Hadoop/img/image-20220103160451159.png" alt="image-20220103160451159" /></p>
</li>
</ol>
<h4 id="3下载"><a class="header" href="#3下载">3.下载</a></h4>
<pre><code class="language-shell">hadoop fs -get /XXX ./
</code></pre>
<h4 id="4执行wordcount程序"><a class="header" href="#4执行wordcount程序">4.执行wordcount程序</a></h4>
<pre><code class="language-sehll">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.1.jar wordcount /wcinput /wcoutput
</code></pre>
<h1 id="配置历史服务器"><a class="header" href="#配置历史服务器">配置历史服务器</a></h1>
<p><strong>3.2以上的版本没配置也能跳转</strong></p>
<pre><code class="language-xml">    &lt;!--历史服务器端地址--&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
        &lt;value&gt;master:10020&lt;/value&gt;
    &lt;/property&gt;
    &lt;!--历史服务器web端地址--&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
        &lt;value&gt;master:19888&lt;/value&gt;
    &lt;/property&gt;
</code></pre>
<p>需要手动启动历史服务器</p>
<pre><code class="language-shell">mapred --daemon start historyserver
</code></pre>
<h1 id="开启日志聚集功能"><a class="header" href="#开启日志聚集功能">开启日志聚集功能！</a></h1>
<p>伪分布式就不用了</p>
<p><img src="bigData/Hadoop/img/image-20220103174805436.png" alt="image-20220103174805436" /></p>
<h1 id="hadoop集群的群起脚本"><a class="header" href="#hadoop集群的群起脚本">hadoop集群的群起脚本</a></h1>
<p>https://www.codetd.com/article/1452178</p>
<div style="break-before: page; page-break-before: always;"></div><img src="bigData/Hadoop/img/image-20220103202221934.png" alt="HDFS概览" style="zoom:70%;float:left" />
<h1 id="第一章-hdfs概述"><a class="header" href="#第一章-hdfs概述">第一章 HDFS概述</a></h1>
<h2 id="11hdfs产出背景及定义"><a class="header" href="#11hdfs产出背景及定义">1.1HDFS产出背景及定义</a></h2>
<ol>
<li>
<p>HDFS产出背景</p>
<p>随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS 只是分布式文件管理系统中的一种。</p>
</li>
<li>
<p>HDFS定义</p>
<p>HDFS（Hadoop Distributed File System），它是一个文件系统，用于存储文件，通过<strong>目录树</strong>来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，<strong>集群中的服务器有各自的角色</strong>。</p>
<p>HDFS 的使用场景：<strong>适合一次写入，多次读出的场景</strong>。一个文件经过创建、写入和关闭之后就不需要改变。</p>
</li>
</ol>
<h2 id="12-hdfs优缺点"><a class="header" href="#12-hdfs优缺点">1.2 HDFS优缺点</a></h2>
<p><u>优点</u>：</p>
<ol>
<li>高容错性
<ol>
<li>数据自动保存多个副本。它通过增加副本的形式，提高容错性。</li>
<li>某一个副本丢失以后，它可以自动恢复。</li>
</ol>
</li>
<li>适合处理大数据
<ol>
<li>数据规模：能够处理数据规模达到GB、TB、甚至<strong>PB</strong>级别的数据。</li>
<li>文件规模：能够处理<strong>百万</strong>规模以上的<strong>文件数量</strong>，数量相当之大。</li>
</ol>
</li>
<li><strong>可构建在廉价机器上</strong>，通过多副本机制，提高可靠性</li>
</ol>
<p><u>缺点</u>：</p>
<ol>
<li>
<p>低时间延迟的访问</p>
<ul>
<li>要求低时间延迟的数据访问的应用，不适合在HDFS上运行，比如毫秒级的存储数据。HDFS是提高数据吞吐量的应用优化的，但可能会以提高时间延迟为代价。</li>
</ul>
</li>
<li>
<p>无法高效的对大量小文件进行存储：</p>
<ul>
<li>存储大量小文件(这里的小文件是指小于HDFS系统的Block大小的文件（默认64M）)的话，它会占用 NameNode大量的内存来存储文件、目录和块信息。这样是不可取的，因为NameNode的内存总是有限的。</li>
<li>由于namenode将文件系统的元数据存储在内存中，因此文件系统所能存储的文件数量受限制于namenode的内存容量。</li>
<li>小文件存储的寻道时间会超过读取时间，它违反了HDFS的设计目标。</li>
</ul>
<pre><code> NN负责文件元数据(属性，块的映射)的管理，NN在运行时，必须将当前集群中存储所有文件的元数据全部加载到内存！NN耗费大量内存！ 而不能存储可观的数据。
 举例： 当前运行NN的机器，有64G内存，除去系统开销，分配给NN50G内存！
 
 文件a (1k), 存储到HDFS上，需要将a文件的元数据保存到NN，加载到内存
 	包括：文件名  创建时间  所属主  所属组 权限 修改时间+ 块的映射(1块)
 	NN占用内存：150B
 	最多存储50G/150B个文件a
 		存储占用磁盘空间：50G/150B * 1k
 	 
 文件b (128M), 存储到HDFS上，需要将b文件的元数据保存到NN，加载到内存
 		包括：文件名  创建时间  所属主  所属组 权限 修改时间+块的映射(1块)
 	NN占用内存：150B
 	最多存储50G/150B个文件b
 		存储占用磁盘空间：50G/150B * 128M

</code></pre>
</li>
<li>
<p>并发写入，文件随机修改：</p>
<ul>
<li>一个文件只能有一个写，不允许多个线程同时写。</li>
<li><strong>仅支持数据 append（追加）</strong>，不支持文件的随机修改。</li>
</ul>
</li>
</ol>
<h2 id="13hdfs组成架构"><a class="header" href="#13hdfs组成架构">1.3HDFS组成架构</a></h2>
<ol>
<li>
<p><code>NameNode（nn）</code>：就是Master，它是一个主管、管理者</p>
<ol>
<li>管理HDFS的名称空间；</li>
<li>配置副本策略；</li>
<li>管理数据块（Block）映射信息；</li>
<li>处理客户端读写请求。 </li>
</ol>
</li>
<li>
<p><code>DataNode（dn）</code>：就是Slave(3.x之后叫worker)。NameNode下达命令，DataNode执行实际的操作</p>
<ol>
<li>存储实际的数据块；</li>
<li>执行数据块的读/写操作。</li>
</ol>
<img src="bigData/Hadoop/img/image-20220104210422466.png" alt="image-20220104210422466" style="zoom:50%" />
</li>
<li>
<p>Client：就是客服端</p>
<ol>
<li>文件切分：文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传；</li>
<li>与NameNode交互，获取文件的位置信息；（允不允许读）</li>
<li>与DataNode交互，读取或者写入数据；</li>
<li>Client提供一些命令来管理HDFS，比如NameNode格式化；</li>
<li>Client可以通过一些命令来访问HDFS，比如对HDFS增删改查操作。</li>
</ol>
</li>
<li>
<p>Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。</p>
<ol>
<li>辅助NameNode，分担其工作。</li>
<li>但是我们以后都会用2个NameNode来代替，因为NameNode有高可用的特性。</li>
</ol>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h4 id="1用公司电脑ssh服务器突然连接不上了之前可以"><a class="header" href="#1用公司电脑ssh服务器突然连接不上了之前可以">1.用公司电脑ssh服务器，突然连接不上了（之前可以）</a></h4>
<img src="bigData/Hadoop/../../../docs/bigData/Hadoop/img/image-20211229153341947.png" alt="image-20211229153341947" style="zoom:50%;" />
<p>ssh -v root@110.42.160.28 ,报错信息如下</p>
<pre><code class="language-shell">C:\02_projects\myGit\learning&gt;ssh -v root@110.42.160.28                                                                                                  
OpenSSH_for_Windows_8.1p1, LibreSSL 3.0.2
debug1: Connecting to 110.42.160.28 [110.42.160.28] port 22.
debug1: connect to address 110.42.160.28 port 22: Connection refused
ssh: connect to host 110.42.160.28 port 22: Connection refused
</code></pre>
<p>用VNC登录，显示<strong>Failed to start OpenSSH server deamon</strong></p>
<p>接着输入sshd -t 检查：显示Missing privilege separation directory: /var/empty/sshd</p>
<p>解决办法：创建一个目录/var/empty/sshd</p>
<pre><code class="language-shell">mkdir /var/empty
mkdir /var/empty/sshd
sshd -t
#重启sshd
systemctl restart sshd
</code></pre>
<img src="bigData/Hadoop/../../../docs/bigData/Hadoop/img/image-20211229162400042.png" alt="image-20211229162400042" style="zoom:50%;" />
<p>后能成功登录</p>
<h4 id="2-伪分布式群起失败"><a class="header" href="#2-伪分布式群起失败">2. 伪分布式群起失败。</a></h4>
<p><img src="bigData/Hadoop/../../../docs/bigData/Hadoop/img/image-20211229164421126.png" alt="image-20211229164421126" /></p>
<p>解决方法:</p>
<p>可以把/home/hadoop/.ssh/known_hosts文件删了，然后重新生成配对密钥即可</p>
<pre><code class="language-shell">sudo apt-get openssh-server
</code></pre>
<pre><code class="language-shell">ssh-keygen -t rsa -P &quot;&quot;
</code></pre>
<pre><code class="language-shell">cat $HOME/.ssh/id_rsa.pub &gt;&gt; $HOME/.ssh/authorized_keys
</code></pre>
<p><a href="https://blog.csdn.net/weixin_30619101/article/details/96996016?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&amp;utm_relevant_index=1">ssh连接所生成的known_hosts出现的问题</a></p>
<h4 id="3-解决云服务器重启后hostname还原的问题"><a class="header" href="#3-解决云服务器重启后hostname还原的问题">3. 解决云服务器重启后，hostname还原的问题</a></h4>
<pre><code class="language-text">查看主机名：hostname
修改主机名：
方法1：sudo hostname xxx 
             但是这是临时的，重启后失效
方法2 ：修改hostname文件，永久修改
              sudo vi /etc/hostname
              重启系统后才会生效
但是，在云服务器上，用方法2设置后，重启后还是会将hostname还原为之前的
需要在在 /etc/cloud/cloud.cfg中将cloud_init_modules中的下面两行删除
-set_hostname
- [update_hostname,once-per-instance]
</code></pre>
<p>linux centos yum报错 To address this issue please refer to the below wiki article 解决方法</p>
<img src="bigData/Hadoop/img/image-20220101212939753.png" alt="image-20220101212939753" style="zoom:33%;float:left" />
<p>报错原因：国外<a href="https://so.csdn.net/so/search?q=yum">yum</a>镜像源 国内下载不了 修改为国内阿里yum镜像源</p>
<p>解决方法：</p>
<pre><code class="language-bash">cd /etc/yum.repos.d/
mkdir repo_bak
mv *.repo repo_bak/
wget http://mirrors.aliyun.com/repo/Centos-7.repo
yum clean all
yum makecache
</code></pre>
<p>详细参考：《<a href="https://so.csdn.net/so/search?q=centos7">centos7</a> 配置国内yum源和epel源》https://blog.csdn.net/whatday/article/details/106107168</p>
<p>解析不不了配置文件中的$releasever</p>
<p><img src="bigData/Hadoop/img/image-20220101213224717.png" alt="image-20220101213224717" /></p>
<pre><code class="language-shell">vim Centos-7.repo
vim CentOS-Base.repo
#用vim的查找替换命令 将$releasever都替换为7（因为我的是centos7）
%s/\$releasever/7/g
</code></pre>
<h4 id="4vim-字符串替换"><a class="header" href="#4vim-字符串替换">4.Vim 字符串替换</a></h4>
<p>查找和替换是任意一款文本编辑器的一组常见和必备功能。下面就来讲解 Vim 中的字符串替换功能。</p>
<p>Vim 使用以下命令结构实现替换功能。</p>
<pre><code>:&lt;range&gt; s/&lt;search_string&gt;/&lt;replace_string&gt;/&lt;modifier&gt;
</code></pre>
<ul>
<li>range - 定义执行“查找和替换”函数的范围，有两个不同的值
<ul>
<li>％ - 对整个文件执行</li>
<li>&lt; start _line &gt; &lt; end_line &gt; - 在一组特定的行上面执行操作</li>
</ul>
</li>
<li>search_string - 需要替换的字符串</li>
<li>replace_string - 替换旧字符串的新字符串</li>
<li>modifier - 确定替换行为，有几个不同的值
<ul>
<li>g - 全局替换</li>
<li>gc - 在每次更换之前要求确认</li>
<li>gn - 忽略替换功能并突出显示查找结果。</li>
</ul>
</li>
</ul>
<h4 id="5namenode无法启动报错原因"><a class="header" href="#5namenode无法启动报错原因">5.NameNode无法启动，报错原因：</a></h4>
<p>1、 java.net.BindException: Port in use: master:9001</p>
<p>2、Caused by: java.net.BindException: Cannot assign requested address</p>
<img src="bigData/Hadoop/img/image-20220101223611130.png" alt="image-20220101223611130" style="zoom:33%;float:left;" />
<p>端口被占用是直接原因，但起因是不能分配所需的地址，跟地址有关的就联想到 /etc/hosts文件</p>
<p>云服务器的IP要换成内网的IP，内网可以比作一个局域网。 </p>
<h4 id="6hadoop集群部署上后在服务器中运行hadoop自带的jar包中的实例报错"><a class="header" href="#6hadoop集群部署上后在服务器中运行hadoop自带的jar包中的实例报错">6.hadoop集群部署上后，在服务器中运行hadoop自带的jar包中的实例报错</a></h4>
<p><img src="bigData/Hadoop/img/image-20220103164220531.png" alt="image-20220103164220531" /></p>
<p>解决方法：按错误提示，在mapred-site.xml配置文件中添加hadoop根目录</p>
<p>1.先运行hadoop classpath得到classpath</p>
<p>将得到的classpath全部复制到mapred-site.xml中，配置</p>
<pre><code class="language-xml">&lt;property&gt; 
    &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;    &lt;value&gt;/home/hadoop/app/hadoop/etc/hadoop:/home/hadoop/app/hadoop/share/hadoop/common/lib/*:/home/hadoop/app/hadoop/share/hadoop/common/*:/home/hadoop/app/hadoop/share/hadoop/hdfs:/home/hadoop/app/hadoop/share/hadoop/hdfs/lib/*:/home/hadoop/app/hadoop/share/hadoop/hdfs/*:/home/hadoop/app/hadoop/share/hadoop/mapreduce/*:/home/hadoop/app/hadoop/share/hadoop/yarn:/home/hadoop/app/hadoop/share/hadoop/yarn/lib/*:/home/hadoop/app/hadoop/share/hadoop/yarn/*
&lt;/value&gt;
&lt;/property&gt;

</code></pre>
<p>配置结束关闭mapred-site.xml</p>
<p>重新启动集群，再在share文件中运行</p>
<h4 id="7-warning-remote-host-identification-has-changed"><a class="header" href="#7-warning-remote-host-identification-has-changed">7. WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!</a></h4>
<p>报错如下</p>
<pre><code>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
ZKK01: @    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
ZKK01: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
ZKK01: IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
ZKK01: Someone could be eavesdropping on you right now (man-in-the-middle attack)!
ZKK01: It is also possible that a host key has just been changed.
ZKK01: The fingerprint for the ECDSA key sent by the remote host is
...
</code></pre>
<p><strong>原因：</strong></p>
<p>因为服务器的ip发生变更了
第一次SSH连接时，会生成一个认证，储存在客户端（也就是用SSH连线其他电脑的那个，自己操作的那个）中的known_hosts，但是如果服务器验证过了，认证资讯当然也会更改，服务器端与客户端不同时，就会跳出错误啦。</p>
<p><strong>解决办法：</strong></p>
<pre><code class="language-shell">输入命令：ssh-keygen -R +输入服务器的IP
</code></pre>
<h4 id="8permission-denied-publickeygssapi-keyexgssapi-with-micpassword问题解决"><a class="header" href="#8permission-denied-publickeygssapi-keyexgssapi-with-micpassword问题解决">8.Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password)问题解决</a></h4>
<p>经过排查发现是没有设置免密登录，解决方案如下：</p>
<pre><code class="language-shell">ssh-keygen -t rsa
cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/authorized_keys
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="常用端口号及配置文件"><a class="header" href="#常用端口号及配置文件">常用端口号及配置文件</a></h1>
<ul>
<li>
<p>hadoop3.x</p>
<ul>
<li>HDFS NameNode 内部常用端口：8020/9000/9820</li>
<li>HDFS NameNode 对用户的查询端口：9870</li>
<li>Yarn查看任务运行情况的：8088</li>
<li>历史服务器：19888</li>
</ul>
</li>
<li>
<p>hadoop2.x</p>
<ul>
<li>HDFS NameNode 内部常用端口：8020/9000</li>
<li>HDFS NameNode 对用户的查询端口：50070</li>
<li>Yarn查看任务运行情况的：8088</li>
<li>历史服务器：19888</li>
</ul>
</li>
<li>
<p>常用配置文件</p>
<ul>
<li>3.x
<ul>
<li>core-site.xml</li>
<li>hdfs-site.xml</li>
<li>yarn-site.xml</li>
<li>mapred-site.xml</li>
<li>wokers</li>
</ul>
</li>
<li>2.x
<ul>
<li>core-site.xml</li>
<li>hdfs-site.xml</li>
<li>yarn-site.xml</li>
<li>mapred-site.xml</li>
<li>slaves </li>
</ul>
</li>
</ul>
</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->

        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </body>
</html>
